# Kopiert fra https://doc.nais.io/observability/alerts/recommended_alerts
apiVersion: "nais.io/v1alpha1"
kind: "Alert"
metadata:
  name: rekrutteringsbistand-api
  labels:
    team: teamtag
spec:
  receivers:
    slack:
      channel: 'tag-inkludering-alerts-dev'
      prependText: '<!here>'
  alerts:
    - alert: Applikasjon nede
      severity: danger
      expr: up{app="rekrutteringsbistand-api", job="kubernetes-pods"} == 0
      for: 2m
      description: "App {{ $labels.app }} er nede i namespace {{ $labels.kubernetes_namespace }}"
      action: "`kubectl describe pod {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for events, og `kubectl logs {{ $labels.kubernetes_pod_name }} -n {{ $labels.kubernetes_namespace }}` for logger"
    - alert: Høy feilrate i logger
      severity: danger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="rekrutteringsbistand-api",log_level=~"Warning|Error"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="rekrutteringsbistand-api"}[3m]))) > 10
      for: 3m
      action: "Sjekk loggene til app {{ $labels.log_app }} i namespace {{ $labels.log_namespace }}, for å se hvorfor det er så mye feil"
    - alert: Feil i selftest
      severity: danger
      expr: selftests_aggregate_result_status{app="rekrutteringsbistand-api"} > 0
      for: 1m
      action: "Sjekk app {{ $labels.app }} i namespace {{ $labels.kubernetes_namespace }} sine selftest for å se hva som er galt"
    # Java-spesifikk
    - alert: Høy feilrate for HTTP-requester
      severity: danger
      expr: (100 * sum by (app, kubernetes_namespace) (rate(jetty_responses_total{app="rekrutteringsbistand-api",code=~"1xx|2xx|3xx"}[3m])) / sum by (app, kubernetes_namespace) (rate(jetty_requests_total{app="rekrutteringsbistand-api"}[3m]))) < 90
      for: 3m
      action: "Sjekk loggene til app {{ $labels.app }} i namespace {{ $labels.kubernetes_namespace }} for å se hvorfor mange HTTP-requests feiler"